{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you will be working with data extracted from famous recommender systems type datasets: you are provided with a large set of interactions between users (persons)  and items (movies). Whenever a user \"interacts\" with an item, it watches the movie and gives a mark or \"rating\": you can interpret a rating of \"1\" as a \"like\", a rating of \"-1\" as a \"dislike\" and a rating of \"0\" as a neutral \"meh\" rating.\n",
    "\n",
    "In this exercise, we will **not** be performing the recommendation task per se. Instead, we will identify *anomalous users*. In the dataset that you are provided with, some of the data was corrupted. Whilst most of the data comes from real life user-item interactions from a famous movie rating website, some \"users\" are anomalous: they were generated by me according to some undisclosed procedure.\n",
    "\n",
    "You are provided with two data frames: the first one (\"ratings\") contains the interactions provided to you, and the second one (\"labels\") contains the labels for the users.\n",
    "\n",
    "As you can see, the three columns in \"ratings\" correspond to the user ID, the item ID and the rating. Thus, each row of \"ratings\" contains a single interaction. For instance, if the row \"142, 152, 1\" is present, this means that the user with ID 142 has given the movie 152 a positive rating of \"1\" (\"like\").\n",
    "\n",
    "The dataframe \"labels\" has two columns. In the first column we have the user ids, whilst the second column contains the labels. A label of 1 indicates that the user is fake (generated by me), whilst a label of 0 denotes a natural user (coming from real life interactions).\n",
    "\n",
    "For instance, if the labels matrix contains the line \"142, 1\", it means that all of the ratings given by the user with id 142 are fake. This means all lines in the dataframe \"ratings\" which start with the userID 142 correspond to fake interactions.\n",
    "\n",
    "Your task is to be able to classify unseen instances as either anomalies or non anomalies (guess whether they are real users or if they were generated by me).\n",
    "\n",
    "There are **far more** normal users than anomalies in the dataset, which makes this a very heavily **unbalanced dataset**. Thus, accuracy will not be a good measure of performance, since simply predicting that every user is normal will give good accuracy. Thus, we need to use some other evaluation metrics.\n",
    "\n",
    "THE **EVALUATION METRICS** are:  THE **AUC** (AREA UNDER CURVE), the **PRECISION**, THE **RECALL**, and the **F1 score**. The **main metric** will be the **AREA UNDER CURVE**, and it will by default be used to rank teams. This means your programs should return an **anomaly score** for each user (the higher the score, the more likely the model think the sample is anomalous)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Methodology\n",
    "## Data Preprocessing:\n",
    "1. Split combined data set into train (train_df) and test (test_df) (80/20)\n",
    "2. Aggregate training data, add more features into it\n",
    "3. Split training data into train (df_X_train/df_y_train) and validation (df_X_val/df_y_val) sets (80/20)\n",
    "4. Normalize training set and validation set\n",
    "\n",
    "## Model Training:\n",
    "1. Apply PCA to training set and validation set\n",
    "2. Conduct SVM training on training set, then apply it onto the validation set, to get the AUC score\n",
    "3. Find optimal threshold\n",
    "4. Find out model performance using the evaluation metrics (Accuracy, Precision, Recall, F1 score)\n",
    "\n",
    "## Model Testing:\n",
    "1. Using test_df that we split from the beginning, apply PCA and conduct aggregation on it\n",
    "2. Apply the SVM model onto test_df and get the AUC score\n",
    "\n",
    "## Model Testing, using fourth data set, to generate csv file:\n",
    "1. Using test_data (fourth_batch_likes.npz), apply PCA and conduct aggregation on it\n",
    "2. Generate predictions and save it into csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "from numpy import argmax\n",
    "\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import iqr\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import entropy\n",
    "from scipy.stats import mode\n",
    "from scipy.stats import gmean\n",
    "from scipy.stats import hmean\n",
    "from scipy.stats import sem\n",
    "from scipy.stats import gstd\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Preprocessing:\n",
    "1. Combine all data sets together\n",
    "2. Split combined data set into train (train_df) and test (test_df) (80/20)\n",
    "3. Aggregate training data, add more features into it\n",
    "4. Split training data into train (df_X_train/df_y_train) and validation (df_X_val/df_y_val) sets (80/20)\n",
    "5. Normalize training set and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Combine all data sets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1220</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1220</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1220</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1220</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1220</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786631</th>\n",
       "      <td>5071</td>\n",
       "      <td>141</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786632</th>\n",
       "      <td>5071</td>\n",
       "      <td>158</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786633</th>\n",
       "      <td>5071</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786634</th>\n",
       "      <td>5071</td>\n",
       "      <td>181</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786635</th>\n",
       "      <td>5071</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>786636 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user  item  rating  label\n",
       "0       1220     6       0      0\n",
       "1       1220    21       1      0\n",
       "2       1220    31       0      0\n",
       "3       1220    33       0      0\n",
       "4       1220    35      -1      0\n",
       "...      ...   ...     ...    ...\n",
       "786631  5071   141      -1      1\n",
       "786632  5071   158      -1      1\n",
       "786633  5071   176       0      1\n",
       "786634  5071   181      -1      1\n",
       "786635  5071   183       0      1\n",
       "\n",
       "[786636 rows x 4 columns]"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the first batch\n",
    "filenames = [\"first_batch_with_labels_likes.npz\", \"second_batch_with_labels_likes.npz\", \"third_batch_with_labels_likes.npz\", \"fourth_batch_with_labels_likes.npz\"]\n",
    "def merge_datasets(filenames: list[str]) -> pd.DataFrame:\n",
    "    merged_df = pd.DataFrame()\n",
    "    for s in filenames:\n",
    "        data = np.load(s)\n",
    "        X1, y1 = data[\"X\"], data[\"y\"]\n",
    "        XX1, yy1 = pd.DataFrame(X1), pd.DataFrame(y1)\n",
    "        XX1.rename(columns={0: \"user\", 1: \"item\", 2: \"rating\"}, inplace=True)\n",
    "        yy1.rename(columns={0: \"user\", 1: \"label\"}, inplace=True)\n",
    "        merged_df = pd.concat([merged_df, pd.merge(XX1, yy1, on='user')], ignore_index=True)\n",
    "    return merged_df\n",
    "\n",
    "combined_data = merge_datasets(filenames)\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split combined data set into train (train_df) and test (test_df) (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 625256\n",
      "test size: 161380\n"
     ]
    }
   ],
   "source": [
    "# Get a list of unique users\n",
    "unique_users = combined_data['user'].unique()\n",
    "\n",
    "# Split the data into train and test sets (80/20)\n",
    "train, test = train_test_split(unique_users, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create dataframes for train and test sets\n",
    "train_df = combined_data[combined_data['user'].isin(train)]\n",
    "test_df = combined_data[combined_data['user'].isin(test)]\n",
    "\n",
    "# Count the number of users in the train and test sets\n",
    "print(f'train size: {len(train_df)}\\ntest size: {len(test_df)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Aggregate training data, add more features into it\n",
    "### I will aggregate the training data first, then split it into train and validation later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_rating_stats(X, y):\n",
    "    unique_items = X.item.unique() #unique movies\n",
    "    columns = np.append(unique_items, 'label')\n",
    "    result = pd.DataFrame(columns=columns)\n",
    "    lst = []\n",
    "    total = len(X.item.unique())\n",
    "\n",
    "    for user in X.user.unique():\n",
    "        ratings = X[X['user'] == user]['rating'] # ratings by single user\n",
    "        ratings_df = X[X['user'] == user] # user -> item -> rating df for single user\n",
    "        ratings_df.loc[:, 'item'] = ratings_df['item'].astype(str) # convert movie id from number to string\n",
    "        ratings_dict = dict(zip(ratings_df.item, ratings_df.rating))\n",
    "        label = y[y['user'] == user].iloc[0]['label']\n",
    "        ratings_dict['label'] = label\n",
    "        ratings_dict['user'] = user\n",
    "        ratings_dict['nan_count'] = total - len(ratings)\n",
    "        ratings_dict['nan_proportion_of_total'] = (total - len(ratings)) / total\n",
    "        ratings_dict['rating_count'] = len(ratings)\n",
    "        ratings_dict['rating_proportion_of_total'] = len(ratings) / total\n",
    "        ratings_dict['rating_mean'] = np.mean(ratings)\n",
    "        ratings_dict['rating_sem'] = sem(ratings)\n",
    "        ratings_dict['rating_sd'] = np.std(ratings)\n",
    "        ratings_dict['rating_variance'] = np.var(ratings)\n",
    "        ratings_dict['rating_sum'] = sum(ratings)\n",
    "        ratings_dict['negative_count'] = sum(rating < 0 for rating in ratings)\n",
    "        ratings_dict['negative_proportion'] = sum(rating < 0 for rating in ratings) / len(ratings)\n",
    "        ratings_dict['negative_proportion_of_total'] = sum(rating < 0 for rating in ratings) / total\n",
    "        ratings_dict['neutral_count'] = sum(rating == 0 for rating in ratings)\n",
    "        ratings_dict['neutral_proportion'] = sum(rating == 0 for rating in ratings) / len(ratings)\n",
    "        ratings_dict['neutral_proportion_of_total'] = sum(rating == 0 for rating in ratings) / total\n",
    "        ratings_dict['positive_count'] = sum(rating > 0 for rating in ratings)\n",
    "        ratings_dict['positive_proportion'] = sum(rating > 0 for rating in ratings) / len(ratings)\n",
    "        ratings_dict['positive_proportion_of_total'] = sum(rating > 0 for rating in ratings) / total\n",
    "        ratings_dict['skew'] = skew(ratings)\n",
    "        ratings_dict['entropy'] = entropy([ratings_dict['negative_proportion_of_total'], ratings_dict['positive_proportion_of_total'], 1-ratings_dict['negative_proportion_of_total']- ratings_dict['positive_proportion_of_total']])\n",
    "        ratings_dict['kurtosis'] = kurtosis(ratings)\n",
    "        ratings_dict['iqr'] = iqr(ratings)\n",
    "        lst.append(ratings_dict)\n",
    "\n",
    "    result = pd.concat([result, pd.DataFrame(lst)], ignore_index=True)\n",
    "    result = result.fillna(-1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinha\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "C:\\Users\\jinha\\AppData\\Local\\Temp/ipykernel_15672/1597720225.py:34: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  ratings_dict['skew'] = skew(ratings)\n",
      "C:\\Users\\jinha\\AppData\\Local\\Temp/ipykernel_15672/1597720225.py:36: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  ratings_dict['kurtosis'] = kurtosis(ratings)\n"
     ]
    }
   ],
   "source": [
    "# Split training data into X and y\n",
    "XX_train = train_df[['user', 'item', 'rating']]\n",
    "yy_train = train_df[['user', 'label']]\n",
    "\n",
    "# Apply aggregation function to training data\n",
    "df1 = agg_rating_stats(XX_train, yy_train)\n",
    "# df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper method to convert probabilities & thresholds to binary values\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Split training data into train (df_X_train/df_y_train) and validation (df_X_val/df_y_val) sets (60/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_XXX = df1.drop(['user', 'label'], axis=1)\n",
    "df1_yyy = df1.label\n",
    "\n",
    "# Columns\n",
    "X_cols = df1_XXX.columns\n",
    "y_col = df1_XXX.columns\n",
    "\n",
    "# Split training set into train and validation sets (80/20)\n",
    "df_X_train, df_X_val, df_y_train, df_y_val = train_test_split(df1_XXX, df1_yyy, stratify=df1_yyy, test_size=0.25, random_state=42) #Change to 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Normalize training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize input variables\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "df_X_train_normalized = pd.DataFrame(scaler.fit_transform(df_X_train), columns=X_cols)\n",
    "df_X_val_normalized = pd.DataFrame(scaler.transform(df_X_val), columns=X_cols) # good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Training:\n",
    "1. Apply PCA to training set and validation set\n",
    "2. Conduct SVM training on training set, then apply it onto the validation set, to get the AUC score\n",
    "3. Find optimal threshold\n",
    "4. Find out model performance using the evaluation metrics (Accuracy, Precision, Recall, F1 score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Apply PCA to training set and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Conduct SVM training on training set, then apply it onto the validation set, to get the AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pc=PCA(n_components=19, svd_solver='full')\n",
    "kpc = KernelPCA(n_components=34, eigen_solver='dense', kernel='rbf',gamma=0.00041)\n",
    "X_train_PC = kpc.fit_transform(df_X_train_normalized)\n",
    "X_val_PC = kpc.transform(df_X_val_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9594395493283259\n"
     ]
    }
   ],
   "source": [
    "# Fit model \n",
    "svc = svm.SVC(class_weight='balanced', probability=True, C=1.5, gamma=21.85, shrinking=False, decision_function_shape='ovr', break_ties=True)\n",
    "svc.fit(X_train_PC, df_y_train)\n",
    "predictions = svc.predict_proba(X_val_PC)[:, 1]\n",
    "auc = roc_auc_score(df_y_val, predictions)\n",
    "print(auc)\n",
    "#0.959352"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold=0.403, F-Score=0.80851\n"
     ]
    }
   ],
   "source": [
    "### find optimal threshold\n",
    "thresholds = arange(0, 1, 0.001)\n",
    "scores = [f1_score(df_y_val, to_labels(predictions, t)) for t in thresholds]\n",
    "ix = argmax(scores)\n",
    "print('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], scores[ix]))\n",
    "svc_threshold = thresholds[ix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Find out model performance using the evaluation metrics (Accuracy, Precision, Recall, F1 score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9117647058823529\n",
      "precision = 0.8837209302325582\n",
      "recall = 0.7450980392156863\n",
      "f1 score = 0.8085106382978724\n"
     ]
    }
   ],
   "source": [
    "### evaluate model performance\n",
    "predicted_labels = to_labels(predictions, svc_threshold)\n",
    "\n",
    "conf_matrix = confusion_matrix(predicted_labels, df_y_val)\n",
    "\n",
    "# Retrieve TN, FN, TP and FP\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "# accuracy = (correct predictions) / (all predictions)\n",
    "accuracy = (tn + tp) / (tn + fn + tp + fp)\n",
    "print('accuracy =', accuracy)\n",
    "\n",
    "# precision = proportion of correct 'true' predictions\n",
    "precision = tp / (tp + fp)\n",
    "print('precision =', precision)\n",
    "\n",
    "# recall = proportion of true records correctly identified\n",
    "recall = tp / (tp + fn)\n",
    "print('recall =', recall)\n",
    "\n",
    "# f1_score = 2*P*R / P+R\n",
    "f1 = (2 * precision * recall) / (precision + recall)\n",
    "print('f1 score =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Testing:\n",
    "1. Using test_df that we split from the beginning, apply PCA and conduct aggregation on it\n",
    "2. Apply the SVM model onto test_df and get the AUC score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using test_df that we split from the beginning, apply PCA and conduct aggregation on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to process test data (No label)\n",
    "def agg_test_stats(X):\n",
    "    result = pd.DataFrame(columns=X_cols)\n",
    "    lst = []\n",
    "    total = len(X.item.unique())\n",
    "\n",
    "    for user in X.user.unique():\n",
    "        ratings = X[X['user'] == user]['rating']\n",
    "        ratings_df = X[X['user'] == user]\n",
    "        ratings_df.loc[:, 'item'] = ratings_df['item'].astype(str)\n",
    "        ratings_dict = dict(zip(ratings_df.item, ratings_df.rating))\n",
    "        ratings_dict['user'] = user\n",
    "        ratings_dict['nan_count'] = total - len(ratings)\n",
    "        ratings_dict['nan_proportion_of_total'] = (total - len(ratings)) / total\n",
    "        ratings_dict['rating_count'] = len(ratings)\n",
    "        ratings_dict['rating_proportion_of_total'] = len(ratings) / total\n",
    "        ratings_dict['rating_mean'] = np.mean(ratings)\n",
    "        ratings_dict['rating_sem'] = sem(ratings)\n",
    "        ratings_dict['rating_sd'] = np.std(ratings)\n",
    "        ratings_dict['rating_variance'] = np.var(ratings)\n",
    "        ratings_dict['rating_sum'] = sum(ratings)\n",
    "        ratings_dict['negative_count'] = sum(rating < 0 for rating in ratings)\n",
    "        ratings_dict['negative_proportion'] = sum(rating < 0 for rating in ratings) / len(ratings)\n",
    "        ratings_dict['negative_proportion_of_total'] = sum(rating < 0 for rating in ratings) / total\n",
    "        ratings_dict['neutral_count'] = sum(rating == 0 for rating in ratings)\n",
    "        ratings_dict['neutral_proportion'] = sum(rating == 0 for rating in ratings) / len(ratings)\n",
    "        ratings_dict['neutral_proportion_of_total'] = sum(rating == 0 for rating in ratings) / total\n",
    "        ratings_dict['positive_count'] = sum(rating > 0 for rating in ratings)\n",
    "        ratings_dict['positive_proportion'] = sum(rating > 0 for rating in ratings) / len(ratings)\n",
    "        ratings_dict['positive_proportion_of_total'] = sum(rating > 0 for rating in ratings) / total\n",
    "        ratings_dict['skew'] = skew(ratings)\n",
    "        ratings_dict['entropy'] = entropy([ratings_dict['negative_proportion_of_total'], ratings_dict['positive_proportion_of_total'], 1-ratings_dict['negative_proportion_of_total']- ratings_dict['positive_proportion_of_total']])\n",
    "        ratings_dict['kurtosis'] = kurtosis(ratings)\n",
    "        ratings_dict['iqr'] = iqr(ratings)\n",
    "        lst.append(ratings_dict)\n",
    "\n",
    "    result = pd.concat([result, pd.DataFrame(lst)], ignore_index=True)\n",
    "    result = result.fillna(-1)  # arbitrarily fill empty values\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinha\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "C:\\Users\\jinha\\AppData\\Local\\Temp/ipykernel_15672/2639459121.py:31: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  ratings_dict['skew'] = skew(ratings)\n",
      "C:\\Users\\jinha\\AppData\\Local\\Temp/ipykernel_15672/2639459121.py:33: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  ratings_dict['kurtosis'] = kurtosis(ratings)\n"
     ]
    }
   ],
   "source": [
    "XX_test = test_df[['user', 'item', 'rating']]\n",
    "yy_test = test_df[['user', 'label']]\n",
    "\n",
    "# XX_test.count()\n",
    "# yy_test.count()\n",
    "\n",
    "# Apply aggregation function to test data\n",
    "df2 = agg_test_stats(XX_test)\n",
    "# df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinha\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but KernelPCA was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "XX_test_1 = df2[df2.columns.intersection(X_cols)]\n",
    "XX_test_normalized = scaler.transform(XX_test_1)\n",
    "# XX_test_poly = poly.transform(XX_test_scaled)\n",
    "XX_test_PC = kpc.transform(XX_test_normalized) #pc from training. Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows in yy_test\n",
    "yy_test = yy_test.drop_duplicates(subset=['user'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Apply the SVM model onto test_df and get the AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956306819402953"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = svc.predict_proba(XX_test_PC)[:, 1]\n",
    "\n",
    "# Evaluation metrics: AUC, Precision, Recall, F1\n",
    "roc_auc_score(yy_test['label'], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Testing, using fourth data set, to generate csv file:\n",
    "1. Using test_data (fourth_batch_likes.npz), apply PCA and conduct aggregation on it\n",
    "2. Generate predictions and save it into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5233</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5233</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5233</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5233</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5233</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285563</th>\n",
       "      <td>6973</td>\n",
       "      <td>456</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285564</th>\n",
       "      <td>6973</td>\n",
       "      <td>461</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285565</th>\n",
       "      <td>6973</td>\n",
       "      <td>477</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285566</th>\n",
       "      <td>6973</td>\n",
       "      <td>486</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285567</th>\n",
       "      <td>6973</td>\n",
       "      <td>490</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285568 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user  item  rating\n",
       "0       5233     0       1\n",
       "1       5233     9       0\n",
       "2       5233    19       1\n",
       "3       5233    24       0\n",
       "4       5233    25       0\n",
       "...      ...   ...     ...\n",
       "285563  6973   456       0\n",
       "285564  6973   461      -1\n",
       "285565  6973   477       1\n",
       "285566  6973   486      -1\n",
       "285567  6973   490       1\n",
       "\n",
       "[285568 rows x 3 columns]"
      ]
     },
     "execution_count": 755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.load(\"fifth_batch_likes.npz\")\n",
    "df_X_test = pd.DataFrame(test_data[\"X\"])\n",
    "df_X_test.rename(columns={0: \"user\", 1: \"item\", 2: \"rating\"}, inplace=True)\n",
    "df_X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using test_data (fourth_batch_likes.npz), apply PCA and conduct aggregation on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinha\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "C:\\Users\\jinha\\AppData\\Local\\Temp/ipykernel_15672/2639459121.py:31: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  ratings_dict['skew'] = skew(ratings)\n",
      "C:\\Users\\jinha\\AppData\\Local\\Temp/ipykernel_15672/2639459121.py:33: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  ratings_dict['kurtosis'] = kurtosis(ratings)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>21</th>\n",
       "      <th>31</th>\n",
       "      <th>33</th>\n",
       "      <th>35</th>\n",
       "      <th>40</th>\n",
       "      <th>54</th>\n",
       "      <th>56</th>\n",
       "      <th>58</th>\n",
       "      <th>60</th>\n",
       "      <th>...</th>\n",
       "      <th>neutral_proportion</th>\n",
       "      <th>neutral_proportion_of_total</th>\n",
       "      <th>positive_count</th>\n",
       "      <th>positive_proportion</th>\n",
       "      <th>positive_proportion_of_total</th>\n",
       "      <th>skew</th>\n",
       "      <th>entropy</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>iqr</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.014042</td>\n",
       "      <td>16</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.016048</td>\n",
       "      <td>-0.483419</td>\n",
       "      <td>0.118905</td>\n",
       "      <td>-1.009389</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.022066</td>\n",
       "      <td>21</td>\n",
       "      <td>0.295775</td>\n",
       "      <td>0.021063</td>\n",
       "      <td>0.184616</td>\n",
       "      <td>0.229560</td>\n",
       "      <td>-1.506980</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292818</td>\n",
       "      <td>0.053159</td>\n",
       "      <td>123</td>\n",
       "      <td>0.679558</td>\n",
       "      <td>0.123370</td>\n",
       "      <td>-1.180968</td>\n",
       "      <td>0.404483</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278912</td>\n",
       "      <td>0.082247</td>\n",
       "      <td>184</td>\n",
       "      <td>0.625850</td>\n",
       "      <td>0.184554</td>\n",
       "      <td>-1.092831</td>\n",
       "      <td>0.600426</td>\n",
       "      <td>-0.022625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.006018</td>\n",
       "      <td>53</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.053159</td>\n",
       "      <td>-2.813062</td>\n",
       "      <td>0.222070</td>\n",
       "      <td>7.260394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402778</td>\n",
       "      <td>0.203611</td>\n",
       "      <td>243</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.243731</td>\n",
       "      <td>-0.609432</td>\n",
       "      <td>0.760435</td>\n",
       "      <td>-0.724940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7095.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518797</td>\n",
       "      <td>0.069208</td>\n",
       "      <td>29</td>\n",
       "      <td>0.218045</td>\n",
       "      <td>0.029087</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.282563</td>\n",
       "      <td>-0.914102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.067202</td>\n",
       "      <td>111</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.111334</td>\n",
       "      <td>-0.824700</td>\n",
       "      <td>0.456293</td>\n",
       "      <td>-0.533641</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7097.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276316</td>\n",
       "      <td>0.021063</td>\n",
       "      <td>25</td>\n",
       "      <td>0.328947</td>\n",
       "      <td>0.025075</td>\n",
       "      <td>0.125341</td>\n",
       "      <td>0.251462</td>\n",
       "      <td>-1.598751</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7098.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.008024</td>\n",
       "      <td>11</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.011033</td>\n",
       "      <td>-0.730709</td>\n",
       "      <td>0.075139</td>\n",
       "      <td>-0.544922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7099.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1022 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        6   21   31   33   35   40   54   56   58   60  ...  \\\n",
       "893  -1.0 -1.0  1.0 -1.0 -1.0 -1.0  1.0  0.0  1.0 -1.0  ...   \n",
       "1354 -1.0  1.0 -1.0 -1.0 -1.0 -1.0 -1.0  0.0  1.0 -1.0  ...   \n",
       "1223  1.0  1.0  1.0 -1.0  1.0  1.0  1.0  0.0  1.0 -1.0  ...   \n",
       "809  -1.0  1.0  1.0  0.0 -1.0 -1.0  0.0  1.0  1.0  1.0  ...   \n",
       "564  -1.0  1.0  1.0 -1.0 -1.0 -1.0  1.0 -1.0 -1.0 -1.0  ...   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "609   0.0  1.0  1.0 -1.0  0.0  1.0  1.0  0.0  1.0  1.0  ...   \n",
       "389  -1.0 -1.0  1.0 -1.0 -1.0  0.0 -1.0 -1.0  1.0 -1.0  ...   \n",
       "1057  1.0  1.0 -1.0 -1.0 -1.0  0.0  0.0 -1.0 -1.0 -1.0  ...   \n",
       "1882 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ...   \n",
       "482  -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  0.0 -1.0  ...   \n",
       "\n",
       "      neutral_proportion  neutral_proportion_of_total  positive_count  \\\n",
       "893             0.388889                     0.014042              16   \n",
       "1354            0.309859                     0.022066              21   \n",
       "1223            0.292818                     0.053159             123   \n",
       "809             0.278912                     0.082247             184   \n",
       "564             0.098361                     0.006018              53   \n",
       "...                  ...                          ...             ...   \n",
       "609             0.402778                     0.203611             243   \n",
       "389             0.518797                     0.069208              29   \n",
       "1057            0.333333                     0.067202             111   \n",
       "1882            0.276316                     0.021063              25   \n",
       "482             0.380952                     0.008024              11   \n",
       "\n",
       "      positive_proportion  positive_proportion_of_total      skew   entropy  \\\n",
       "893              0.444444                      0.016048 -0.483419  0.118905   \n",
       "1354             0.295775                      0.021063  0.184616  0.229560   \n",
       "1223             0.679558                      0.123370 -1.180968  0.404483   \n",
       "809              0.625850                      0.184554 -1.092831  0.600426   \n",
       "564              0.868852                      0.053159 -2.813062  0.222070   \n",
       "...                   ...                           ...       ...       ...   \n",
       "609              0.482143                      0.243731 -0.609432  0.760435   \n",
       "389              0.218045                      0.029087  0.059781  0.282563   \n",
       "1057             0.552239                      0.111334 -0.824700  0.456293   \n",
       "1882             0.328947                      0.025075  0.125341  0.251462   \n",
       "482              0.523810                      0.011033 -0.730709  0.075139   \n",
       "\n",
       "      kurtosis  iqr    user  \n",
       "893  -1.009389  1.0  5100.0  \n",
       "1354 -1.506980  2.0  5101.0  \n",
       "1223  0.373424  1.0  5102.0  \n",
       "809  -0.022625  1.0  5103.0  \n",
       "564   7.260394  0.0  5104.0  \n",
       "...        ...  ...     ...  \n",
       "609  -0.724940  1.0  7095.0  \n",
       "389  -0.914102  1.0  7096.0  \n",
       "1057 -0.533641  1.0  7097.0  \n",
       "1882 -1.598751  2.0  7098.0  \n",
       "482  -0.544922  1.0  7099.0  \n",
       "\n",
       "[2000 rows x 1022 columns]"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = agg_test_stats(df_X_test)\n",
    "X_test = X_test.sort_values(by=['user'], ascending=True)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'poly' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15672/504437789.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_test_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_test_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_test_poly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX_test_PC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_poly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'poly' is not defined"
     ]
    }
   ],
   "source": [
    "X_test_1 = X_test[X_test.columns.intersection(X_cols)]\n",
    "X_test_scaled = scaler.transform(X_test_1)\n",
    "X_test_poly = poly.transform(X_test_scaled)\n",
    "X_test_PC = pc.transform(X_test_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate predictions and save it into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper method to generate output csv\n",
    "def generate_test_output(users, predictions, opt_threshold, file_name):\n",
    "    predictions =  predictions - opt_threshold \n",
    "    d = {'user': users, 'anomaly_score': predictions}\n",
    "    output_df = pd.DataFrame(data=d)\n",
    "    output_df = output_df.astype({'user':'int'})\n",
    "    output_df.reset_index(drop=True)\n",
    "    output_df = output_df.sort_values(by=['user'])\n",
    "    output_df.to_csv(file_name, index=False, header=False)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = X_test.user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_PC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15672/3664915124.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_PC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moutput_csv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_test_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvc_threshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'answer.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moutput_csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test_PC' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = svc.predict_proba(X_test_PC)[:, 1]\n",
    "predictions.shape\n",
    "output_csv = generate_test_output(users, predictions, svc_threshold, file_name='answer.csv')\n",
    "output_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
